{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МФТИ ФИВТ: Потапова Софья, 394 группа. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Organization Info</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дополнительный материал для выполнения дз**:\n",
    "- Hastie, The Elements of Statistical Learning, https://goo.gl/k3wfEU\n",
    "    - 2.9 Model Selection and the Bias–Variance Tradeoff \n",
    "    - 15 Random Forests\n",
    "- Соколов, Семинары по композиционным методам, https://goo.gl/sn8RyJ\n",
    "- Andrew Ng, Bias vs. Variance, https://goo.gl/1ISZ6Y\n",
    "\n",
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2016_fall <номер_группы> <фамилия>``, к примеру -- ``ML2016_fall 401 ivanov``\n",
    "- Выполненное дз сохраните в файл ``<фамилия>_<группа>_task<номер>.ipnb``, к примеру -- ``ivanov_401_task1.ipnb``\n",
    "\n",
    "**Вопросы**:\n",
    "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2016_fall Question <Содержание вопроса>``\n",
    "\n",
    "--------\n",
    "- **PS1**: Мы используем автоматические фильтры, и просто не найдем ваше дз, если вы не аккуратно его подпишите.\n",
    "- **PS2**: Напоминаем, что дедлайны жесткие, письма пришедшие после автоматически удаляются =( чтобы соблазна не было "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Check Questions</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответе на вопросы своими словами (загугленный материал надо пересказать), ответ обоснуйте (напишите и ОБЪЯСНИТЕ формулки если потребуется), если не выходит, то вернитесь к лекции дополнительным материалам:\n",
    "\n",
    "**Вопрос 1**: Какие формулы у шума, смещения, разброса? Какой смысл у этих компонент?\n",
    "$$Noise = E_{x,y}(a^*(x) - y)^2$$\n",
    "$$Bias = E_{x,y}(a(x) - a^*(x))^2$$\n",
    "$$Variance = E_{x,y}E_{X^l}(\\mu(X^l(x))a(x))^2$$\n",
    "Шум - ошибки в данных, неточности модели.\n",
    "Смещение - показатель, при котором модель будет производить одинаковые ошибки для входа, независимо от обучающего множества. Модель смещает свои собственные предположения о реальных отношениях из-за связей, имеющихся в обучающих данных.\n",
    "Разброс - мера отклонения от математического ожидания. Модель с большим разбросом, наоборот, будет производить различные ошибки для входа в зависимости от обучающего множества.\n",
    "\n",
    "**Вопрос 2**: 4. Приведите пример семейства с маленьким смещением и большим разбросом. Приведите пример семейства с большим смещением и маленьким разбросом.\n",
    "\n",
    "Маленькое смещение + большой разброс - деревья.\n",
    "Болшое смещение и маленький разброс - линейные модели.\n",
    "\n",
    "**Вопрос 3**: Как сгенерировать подвыборку с помощью бутстрапа?\n",
    "\n",
    "Взять l элементов с повторениями (l <= размер выборки).\n",
    "\n",
    "**Вопрос 4**: Что такое бэггинг?\n",
    "\n",
    "Bootstrap Aggregating\n",
    "\n",
    "Базовые алгоритмы b_t(x) обучаются независмо по случайным подвыборкам длины l с повторениями (как в методе bootstrap)\n",
    "\n",
    "**Вопрос 5**:  Как соотносятся смещение разброс композиции, построенной с помощью бэггинга, со смещением и разбросом одного базового алгоритма?\n",
    "\n",
    "Смещение одинаковое, разброс композиции с помощью бэггинга меньше, чем разброс одного базового алгоритма.\n",
    "\n",
    "\n",
    "**Вопрос 6**: Как обучается случайный лес? В чем отличия от обычной процедуры построения решающих деревьев?\n",
    "\n",
    "Беггинг над случайными деревьями, прунинг не производится, для обучения испльзуется подвыборка объектов, признак в каждой вершине дерева выбирается из случайного подмножества признаков (лекции Воронцова).\n",
    "\n",
    "**Вопрос 7**: Почему хорошими базовыми алгоритмами для бэггинга являются именно деревья?\n",
    "\n",
    "На деревьях большой разброс, но маленькое смещение. Поэтому при использовании беггинга становится маленьким и разброс, и смещение, и мы победили. \n",
    "\n",
    "**Вопрос 8**: Как оценить качество случайного леса с помощью out-of-bag-процедуры?\n",
    "\n",
    "out-of-bag нужен для вычисления T - количества деревьев в лесу. Минимизируем число ошибок на объектах x_i, если не учитывать голоса деревьев, для которых x_i был обучающим. Качество случайного леса определяем количеством таких ошибок. \n",
    "\n",
    "\n",
    "-----------\n",
    "PS: Если проверяющий не понял ответ на большинство вопросов, то будет пичалька. Пишите так, чтобы можно было разобраться. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1 align=\"center\">Bagging</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Известно, что бэггинг плохо работает, если в качестве базовых классификаторов взять knn. Попробуем понять причины на простом примере.\n",
    "\n",
    "Пусть дана выборка $X^l$ из $l$ объектов с ответами из множества $Y = \\{−1, +1\\}$. Будем рассматривать классификатор одного ближайшего соседа в качестве базового алгоритма. Построим с помощью бэггинга композицию длины $N$:\n",
    "\n",
    "$$a_N(x) = sign(\\sum_{n=1}^{N} b_n(x))$$\n",
    "\n",
    "Оцените вероятность того, что ответ композиции на произвольном объекте x будет\n",
    "отличаться от ответа одного классификатора ближайшего соседа, обученного по всей\n",
    "выборке. Покажите, что эта вероятность стремится к нулю при N → ∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "**<Решение>**\n",
    "Обозначим за P вероятность, что элемент в выборке. \n",
    "$$P = \\frac{\\overline{C_{k-1}^l}}{\\overline{C_k^l}}$$\n",
    "$$P \\in (0,1)$$\n",
    "Пусть для фиксированного элемента i соседей лежат в том же классе, что и ближайший. Тогда $$(1-P)^i$$ вероятность того, что ближайшие i соседей не попали в выборку. Чтобы ответ композиции на этом элементе\n",
    "отличался от ответа одного классификатора ближайшего соседа, обученного по всей выборке, достаточно, чтоб ближайшие i соседей не попадали в выборку хотя бы в половине случаев. То есть вероятность этого равна\n",
    "$$((1-P)^i)^{N/2}$$, откуда видно, что при стремлении N к бесконечности, вероятность стремится к нулю. Именно поэтому нет смысла запускать беггинг на kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Bagging Implementation</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте беггинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "class BaggingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator, n_estimators, items_rate=0.8, features_rate=0.8):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator: sklearn.Classifier\n",
    "            Базовый алгоритм, который можно обучить (есть метод fit).\n",
    "            Для обучение композиции нужно много таких, можэно получить с помощю copy.deepcopy\n",
    "\n",
    "        n_estimators: int\n",
    "            Число алгоритмов в композиции\n",
    "\n",
    "        items_rate: float > 0\n",
    "            Доля объектов из трейна, на которой будет обучаться каждый базовый алгоритм\n",
    "\n",
    "        features_rate: float > 0\n",
    "            Доля фичей, на которой будет обучаться и применяться каждый базовый алгоритм\n",
    "        \"\"\"\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.items_rate = items_rate\n",
    "        self.features_rate = features_rate\n",
    "        self.class_cnt = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Метод должен обучить композицию алгоритмов, используя X, y как обучающую выборку.\n",
    "        Не забудте реализорвать функционал выбора случайных объектов и фичей.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: 2d np.array\n",
    "        y: 1d np.array\n",
    "        \"\"\"\n",
    "        self.class_cnt = y.max()\n",
    "        \n",
    "        self.estimators = []\n",
    "\n",
    "        self.features_idx = []\n",
    "\n",
    "        items_cnt, features_cnt = X.shape\n",
    "        features_for_estimator = int(features_cnt * self.features_rate)\n",
    "        items_for_estimator = int(items_cnt * self.items_rate)\n",
    "                \n",
    "        for i in range(self.n_estimators):\n",
    "            #print(\"hey\")\n",
    "            estimator = deepcopy(self.base_estimator)\n",
    "            rand_items = np.random.choice(items_cnt, items_for_estimator, replace=True)\n",
    "            rand_features = np.random.choice(features_cnt, features_for_estimator, replace=False)\n",
    "            X_for_est = X[rand_items[:, None], rand_features]\n",
    "            y_for_est = y[rand_items]\n",
    "            estimator.fit(X_for_est, y_for_est)\n",
    "            self.estimators.append(estimator)\n",
    "            self.features_idx.append(rand_features)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: 2d np.array матрица объекты признаки на которых нужно сказать ответ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred: 1d np.array, Вектор классов для каждого объекта\n",
    "        \"\"\"\n",
    "        \n",
    "        probs = [] # Храните тут ответы каждого базового алгоритма \n",
    "\n",
    "        counts = np.zeros((self.class_cnt + 1, X.shape[0]))\n",
    "        for i in range(self.n_estimators):            \n",
    "            probs = self.estimators[i].predict(X[:, self.features_idx[i]])\n",
    "            for j in range(len(probs)):\n",
    "                counts[probs[j]][j] += 1\n",
    "        y_pred = np.argmax(counts, axis=0)\n",
    "        return y_pred\n",
    "    \n",
    "        #return y_pred.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "titanic = pd.read_csv('./data/train.csv')[['Survived', 'Pclass', 'Sex', 'Age', 'Fare']]\n",
    "\n",
    "sex_encoder = LabelEncoder()\n",
    "titanic.Sex = sex_encoder.fit_transform(titanic.Sex)\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = titanic[features].values, titanic.Survived.values\n",
    "X = np.nan_to_num(X)\n",
    "X_train, y_train, X_test, y_test = X[:500], y[:500], X[500:], y[500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно обучить свой беггинг на датасете титаник, и посмотреть работает ли он. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.928 0.808184143223\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Обучите беггинг над DecisionTreeClassifier с 10 моделями\n",
    "# =======================================\n",
    "\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), 10)\n",
    "clf.fit(X_train, y_train)\n",
    "print(accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведите эксперименты:\n",
    "    - Работает-ли беггинг лучше чем просто линейная модель?\n",
    "    - Какой items_rate и features_rate работает лучше и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.99550000000000005, 0.86099832815858612)\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Обучите беггинг над DecisionTreeClassifier с 100 моделями\n",
    "# =======================================\n",
    "\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), 100)\n",
    "clf.fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   34.3s\n",
      "[Parallel(n_jobs=4)]: Done 108 out of 108 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'items_rate': 0.7000000000000001, 'features_rate': 0.5},\n",
      "prediction accuracy: 0.859326486745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "grid_searcher = GridSearchCV(clf, scoring='accuracy', iid=False, cv=3, verbose=1, n_jobs=4,\n",
    "param_grid={'items_rate':[0.1 * i for i in range(1,10)], 'features_rate':[0.25 * i for i in range(1,5)]})\n",
    "grid_searcher.fit(X_train, y_train)\n",
    "print('best params: %s,\\nprediction accuracy: %s' % (\n",
    "grid_searcher.best_params_, accuracy_score(grid_searcher.best_estimator_.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9487 0.852559509593\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(DecisionTreeClassifier(), 10, 0.7, 0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.80000000000000004, 0.76982097186700771)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: бэггинг работает лучше, чем линейная модель. items_rate = 0.7, features_rate = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult = pd.read_csv(\n",
    "    './data/adult.data', \n",
    "    names=[\n",
    "        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n",
    "        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n",
    "        \"Hours per week\", \"Country\", \"Target\"], \n",
    "    header=None, na_values=\"?\")\n",
    "\n",
    "adult = pd.get_dummies(adult)\n",
    "adult[\"Target\"] = adult[\"Target_ >50K\"]\n",
    "X, y = adult[adult.columns[:-3]].values, adult[adult.columns[-1]].values\n",
    "X_train, y_train, X_test, y_test = X[:20000], y[:20000], X[20000:], y[20000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответте на вопросы:\n",
    "    - Работает-ли беггинг лучше чем просто линейная модель?\n",
    "    - Какой items_rate и features_rate работает лучше и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.99695, 0.86020221319958601)\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(DecisionTreeClassifier(), 100)\n",
    "clf.fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=4)]: Done 108 out of 108 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'items_rate': 0.5, 'features_rate': 0.5},\n",
      "prediction accuracy: 0.857575033835\n"
     ]
    }
   ],
   "source": [
    "grid_searcher = GridSearchCV(clf, scoring='accuracy', iid=False, cv=3, verbose=1, n_jobs=4,\n",
    "param_grid={'items_rate':[0.1 * i for i in range(1,10)], 'features_rate':[0.25 * i for i in range(1,5)]})\n",
    "grid_searcher.fit(X_train, y_train)\n",
    "print('best params: %s,\\nprediction accuracy: %s' % (\n",
    "grid_searcher.best_params_, accuracy_score(grid_searcher.best_estimator_.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.94325000000000003, 0.85964493272828602)\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(DecisionTreeClassifier(), 100, 0.5, 0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.79990000000000006, 0.79515962104927951)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: беггинг работает лучше линейной модели. items_rate = feature_rate = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Text, Image Classification</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше в каждом эксперименте нужно: \n",
    "- сравниться с линейной моделью ( какую лучше выбрать?=) )\n",
    "- сделать выбор в пользу одной из моделей\n",
    "- выбор обосновать, почему одна из моделей хуже а другая лучше\n",
    "- что такое хуже и лучше\n",
    "- попробуйте беггинг над деревьями и линейными моделями \n",
    "- почему работает или не работает, какие особенности данных на это влияют"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train, y_train = vectorizer.fit_transform(newsgroups_train.data), newsgroups_train.target\n",
    "X_test,  y_test  = vectorizer.transform(newsgroups_test.data), newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969860350009 0.827934147637\n",
      "CPU times: user 17.7 s, sys: 1min 22s, total: 1min 40s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# =======================================\n",
    "# Обучите Линейную модель \n",
    "# =======================================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "print(accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925 0.465215082315\n",
      "CPU times: user 53.3 s, sys: 1.73 s, total: 55 s\n",
      "Wall time: 55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# =======================================\n",
    "# Обучите беггинг над DecisionTreeClassifier\n",
    "# =======================================\n",
    "\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), 10, 0.5, 0.5)\n",
    "clf.fit(X_train[:10000], y_train[:10000])\n",
    "print(accuracy_score(clf.predict(X_train[:10000]), y_train[:10000]), accuracy_score(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.823 0.376128518322\n",
      "CPU times: user 56.3 s, sys: 32.7 s, total: 1min 28s\n",
      "Wall time: 55.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# =======================================\n",
    "# Обучите беггинг над DecisionTreeClassifier\n",
    "# =======================================\n",
    "\n",
    "clf = BaggingClassifier(LogisticRegression(), 10, 0.5, 0.5)\n",
    "clf.fit(X_train[:1000], y_train[:1000])\n",
    "print(accuracy_score(clf.predict(X_train[:1000]), y_train[:1000]), accuracy_score(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь мы видим, что регрессия работает лучше, потому что количество фич достаточно велико, смещение мало, и фичи очень важны в анализе текстов(поэтому бэггинг плохо работает)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_cifar10(base='./data/cifar10'):\n",
    "    def load_CIFAR_batch(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            datadict = pickle.load(f, encoding='latin1')\n",
    "            Y = np.array(datadict['labels'])\n",
    "            X = datadict['data'].reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype(\"float\")\n",
    "            return X, Y\n",
    "\n",
    "    def load_CIFAR10(ROOT):\n",
    "        xs, ys = [], []\n",
    "        for b in range(1, 6):\n",
    "            f = os.path.join(ROOT, 'data_batch_%d' % (b,))\n",
    "            X, Y = load_CIFAR_batch(f)\n",
    "            xs.append(X)\n",
    "            ys.append(Y)\n",
    "        Xtr, Ytr = np.concatenate(xs), np.concatenate(ys)\n",
    "        del X, Y\n",
    "        Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "        return Xtr, Ytr, Xte, Yte\n",
    "\n",
    "    cifar10_dir = os.path.join(base, 'cifar-10-batches-py')\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    # Transpose so that channels come first\n",
    "    X_train = X_train.transpose(0, 3, 1, 2).copy()\n",
    "    X_test = X_test.transpose(0, 3, 1, 2).copy()\n",
    "\n",
    "    X_val, y_val = X_test, y_test\n",
    "\n",
    "    return (X_train, y_train, X_val, y_val, X_test, y_test), X_train.shape[0], X_test.shape[0], (None, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10('./data/cifar10')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test = X_train.reshape(X_train.shape[0], -1), X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -71.71074,  -87.14036,  -81.05044, ...,   26.16942,  -29.90624,\n",
       "         -42.38186],\n",
       "       [  23.28926,   -4.14036,  -26.05044, ...,   25.16942,   28.09376,\n",
       "          29.61814],\n",
       "       [ 124.28926,  122.85964,  121.94956, ...,  -30.83058,  -30.90624,\n",
       "         -30.38186],\n",
       "       ..., \n",
       "       [-102.71074, -100.14036,  -98.05044, ...,  -13.83058,  -14.90624,\n",
       "         -18.38186],\n",
       "       [   3.28926,    0.85964,   -3.05044, ...,   22.16942,   23.09376,\n",
       "          23.61814],\n",
       "       [  -5.71074,  -20.14036,  -29.05044, ...,  -31.83058,  -29.90624,\n",
       "         -28.38186]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.198\n",
      "CPU times: user 56.7 s, sys: 1.76 ms, total: 56.7 s\n",
      "Wall time: 56.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# =======================================\n",
    "# Обучите Линейную модель \n",
    "# =======================================\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "print(accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.3373\n",
      "CPU times: user 1min 36s, sys: 5.27 s, total: 1min 41s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# =======================================\n",
    "# Обучите беггинг над DecisionTreeClassifier\n",
    "# =======================================\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), 100, 0.5, 0.5)\n",
    "clf.fit(X_train[:2000], y_train[:2000])\n",
    "print(accuracy_score(clf.predict(X_train[:2000]), y_train[:2000]), accuracy_score(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бэггинг выигрывает, несмотря на то, что используем не все фичи для обучения, что важно для картинок.\n",
    "Но вообще результаты очень плохие, так как мы не учитываем соседние пиксели, а фичи между собой очень зависимы в распознавании изображений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Random Forest Feature Impotance</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Опишите как вычисляется важность фичей в дереве, можите изучить как работает  feature\\_importances_ в sklearn.\n",
    "\n",
    "---\n",
    "\n",
    "По выбранному критерию, например, Gini или энтропия. \n",
    "$$IGain(p,n) = h(\\frac{P}{l}) - \\frac{p+n}{l}h(\\frac{p}{p+n}) - \\frac{l - p - n}{l}h(\\frac{P - p}{l - p - n})$$\n",
    "$$h(q) = -q*log_2q - (1-q)*log_2(1-q)$$\n",
    "$$IGini(p,n) = IGain(p,n) при h(q) = 4q(1-q)$$\n",
    "\n",
    "Эти критерии считаются при разбиении на правую и левую, находясь в конкретном узле. Получется, фича тем важнее, чем она лучше разделяет выборку и чем она выше к корню."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Почитайте Feature Impotance для Adult и Titanic (используйте полный датасет), ПРОИНТЕРПРЕТИРУЙТЕ резульататы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = adult[adult.columns[:-3]].values, adult[adult.columns[-1]].values\n",
    "X_train, y_train, X_test, y_test = X[:20000], y[:20000], X[20000:], y[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, \n",
    "                        items_rate=1, features_rate=1).fit(X_train, y_train)\n",
    "importancies = np.zeros(X_train.shape[1])\n",
    "for i in range(100):\n",
    "    importancies[clf.features_idx[i]] += clf.estimators[i].feature_importances_\n",
    "importancies /= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.196999</td>\n",
       "      <td>Martial Status_ Married-civ-spouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.168104</td>\n",
       "      <td>fnlwgt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.113710</td>\n",
       "      <td>Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.110225</td>\n",
       "      <td>Education-Num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104892</td>\n",
       "      <td>Capital Gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.064254</td>\n",
       "      <td>Hours per week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038680</td>\n",
       "      <td>Capital Loss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                            features\n",
       "33  0.196999  Martial Status_ Married-civ-spouse\n",
       "1   0.168104                              fnlwgt\n",
       "0   0.113710                                 Age\n",
       "2   0.110225                       Education-Num\n",
       "3   0.104892                        Capital Gain\n",
       "5   0.064254                      Hours per week\n",
       "4   0.038680                        Capital Loss"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(importancies)\n",
    "df['features'] = np.array(adult.columns)[:-3]\n",
    "df.sort(0, ascending=False)[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('./data/train.csv')[['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Parch']]\n",
    "sex_encoder = LabelEncoder()\n",
    "titanic.Sex = sex_encoder.fit_transform(titanic.Sex)\n",
    "parch_encoder = LabelEncoder()\n",
    "titanic.Parch = parch_encoder.fit_transform(titanic.Parch)\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare', 'Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = titanic[features].values, titanic.Survived.values\n",
    "X = np.nan_to_num(X)\n",
    "X_train, y_train, X_test, y_test = X[:500], y[:500], X[500:], y[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, \n",
    "                        items_rate=1, features_rate=1).fit(X_train, y_train)\n",
    "importancies = np.zeros(X_train.shape[1])\n",
    "for i in range(100):\n",
    "    importancies[clf.features_idx[i]] += clf.estimators[i].feature_importances_\n",
    "importancies /= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.336504</td>\n",
       "      <td>Sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.308132</td>\n",
       "      <td>Fare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.245023</td>\n",
       "      <td>Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.081032</td>\n",
       "      <td>Pclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029308</td>\n",
       "      <td>Parch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0 features\n",
       "1  0.336504      Sex\n",
       "3  0.308132     Fare\n",
       "2  0.245023      Age\n",
       "0  0.081032   Pclass\n",
       "4  0.029308    Parch"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(importancies)\n",
    "df['features'] = np.array(titanic.columns[1:])\n",
    "df.sort(0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
